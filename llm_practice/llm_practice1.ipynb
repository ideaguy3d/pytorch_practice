{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e724a4acd95777f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a43f98b3d86410",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T05:29:31.005182Z",
     "start_time": "2024-02-25T05:29:30.995990Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "tasks = [\n",
    "    'text-classification', 'sentiment-analysis', 'ner', 'fill-mask', \n",
    "    'question-answering', 'translation_xx_to_yy', 'summarization', \n",
    "    'table-question-answering', 'text-generation', 'conversational'\n",
    "]\n",
    "\n",
    "models = ['bert', 'gpt2', 't5', 'xlnet', 'distilbert', 'roberta', 'albert', 'xlm', 'distilgpt2', 'distilroberta', 'flaubert', 'camembert', \n",
    "          'pegasus', 'mbart', 'marian', 't5', 'blenderbot', 'dialogpt', 'reformer', 'prophetnet', 'bart', 'longformer', 'electra', 'funnel',\n",
    "          'deberta', 'ibert', 'luke', 'rag', 'retribert', 'bigbird', 'led', 'mt5', 'pegasus', 'speech-to-text', 'text-to-speech', \n",
    "          'audio-to-audio', 'audio-to-text', 'audio-to-speech', 'speech-to-audio', 'speech-to-text', 'speech-to-speech', 'text-to-audio', \n",
    "          'text-to-speech', 'translation', 'text-translation', 'image-translation', 'image-to-text', 'text-to-image', \n",
    "          'distilbert-base-uncased',]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentiment_classifier = pipeline('sentiment-analysis')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:15:17.836291Z",
     "start_time": "2024-02-25T04:14:43.479071Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reviews = [\n",
    "\"\"\"\n",
    "Dear seller, I got very impressed with the fast\n",
    "delivery and careful packaging of my order. Great\n",
    "experience overall, thank you! \n",
    "\"\"\",\n",
    "\"\"\"\n",
    "This is the worst product took such a long time to\n",
    "get delivered. And on top of that I am not happy with \n",
    "the quality of the the material. \n",
    "\"\"\"    \n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:21:06.626074Z",
     "start_time": "2024-02-25T04:21:06.616969Z"
    }
   },
   "id": "1a1085944b7479a8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9998602867126465}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = sentiment_classifier(reviews[0])\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:21:01.787394Z",
     "start_time": "2024-02-25T04:21:01.742869Z"
    }
   },
   "id": "5ce7b14cbee0d878",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'NEGATIVE', 'score': 0.9998190999031067}]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = sentiment_classifier(reviews[1])\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:20:54.702635Z",
     "start_time": "2024-02-25T04:20:54.651364Z"
    }
   },
   "id": "6824b92f9dea3d37",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# text classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1079124c2c82479f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"Studying day after day after day and so on requires a lot of discipline\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ab6b939874a8a39"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'label': 'POSITIVE', 'score': 0.9085032939910889}]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tc = pipeline(task='text-classification')\n",
    "outputs = llm_tc(text)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:44:48.296999Z",
     "start_time": "2024-02-25T04:44:39.896534Z"
    }
   },
   "id": "d15711c7fbc35c43",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# text generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3e14c2d2fd0a567"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3983ce29b3a641ca9077a767ecf1dd86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afe3f286f7b0443aa78ed86372d36de3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d71bb2f31dc40709c28f43920025a5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76adc3520d154a05a468aabc99b669a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a26e719f3bf64caebbfcb983c898878a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6c0ccb15d954048a5afbc3f78def9f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d60921a7883941a1a7b2da85f1462e99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': \"studying day after day after day and so on requires a lot of discipline and practice. We try not to do too much of it, but we try to put out a few things, and I think it's important to stress how important it is\"}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tg = pipeline(task='text-generation')\n",
    "outputs = llm_tg(text, max_length=100)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:46:04.005517Z",
     "start_time": "2024-02-25T04:45:49.077257Z"
    }
   },
   "id": "a5bac57d583f77ca",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "long_text = \"\"\"\n",
    "In the future, AI could evolve to understand the complex web of human emotions and thoughts with even greater depth, offering more nuanced support and guidance. This doesn't diminish the value of human emotions or the richness they bring to our lives but rather acknowledges them as a fundamental part of our decision-making process. By leveraging AI, we can aspire to a level of self-understanding and emotional intelligence that enhances our capacity for making choices that lead to fulfilling and happy lives, in harmony with our feelings and thoughts. The ultimate goal is not to control or negate emotions but to integrate them intelligently with conscious thought, leveraging the best of both to make choices that contribute to a happier, more balanced life. AI stands as a promising ally in this journey, offering tools and insights to navigate the complex interplay of mind and heart.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:49:19.356279Z",
     "start_time": "2024-02-25T04:49:19.344663Z"
    }
   },
   "id": "934d4c2145c8443e",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# text summarization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f959cd91596bbac"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'summary_text': \" AI could evolve to understand the complex web of human emotions and thoughts with even greater depth. This doesn't diminish the value of human emotion but acknowledges them as a fundamental part of our decision-making process. By leveraging AI, we can aspire to a level of self-understanding and\"}]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_s = pipeline(task='summarization')\n",
    "outputs = llm_s(long_text, max_length=60, clean_up_tokenization_spaces=True)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T04:52:19.416223Z",
     "start_time": "2024-02-25T04:52:02.616771Z"
    }
   },
   "id": "174df89529c53c7a",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# question answering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e48afd45118aa8d9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d82a39da0714d4e9d417c94e67825ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "258428cafd9a4590a389daa92a79b435"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c3f9c5581d44a24a565c3f1ac054356"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c9a354ea1a3403c99264a1dbb2dbea3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da1c586209d6499b8764eca7497e9aae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'score': 0.47816920280456543,\n 'start': 486,\n 'end': 512,\n 'answer': 'fulfilling and happy lives'}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_qa = pipeline(task='question-answering')\n",
    "outputs = llm_qa(question=\"What is the ultimate goal?\", context=long_text)\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T05:03:35.196617Z",
     "start_time": "2024-02-25T05:03:27.936158Z"
    }
   },
   "id": "fe0044c0b3d41416",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch transformer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "699076b8422c2843"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model embedding dimension \n",
    "d_model = 512\n",
    "# number of attention heads\n",
    "n_heads = 8\n",
    "# number of encoder and decoder layers\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T05:30:49.200842Z",
     "start_time": "2024-02-25T05:30:49.190812Z"
    }
   },
   "id": "5341c2336593733e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Transformer(\n",
    "    d_model=d_model, \n",
    "    nhead=n_heads, \n",
    "    num_encoder_layers=num_encoder_layers, \n",
    "    num_decoder_layers=num_decoder_layers\n",
    ")\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T05:31:34.402707Z",
     "start_time": "2024-02-25T05:31:33.748114Z"
    }
   },
   "id": "d28cd7eef77e096a",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc695715f37a38ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "19b068e1cde22e6b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a3c9ef36922710a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b4fa8fedc96dffd7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "132b08a5aa9cbe2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
